{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization and Multivariate Calculus\n",
    "\n",
    "We will use optimization to motivate the development of multivariate calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate calculus\n",
    "\n",
    "- For a sufficiently smooth scalar function $f: \\mathbb{R} \\mapsto \\mathbb{R}$, we have the second order Taylor approximation:  \n",
    "$$\n",
    "f(x + \\Delta x) \\approx f(x) + \\Delta x \\frac{d}{dx}f(x) + \\frac 12 (\\Delta x)^2 \\frac{d^2}{dx^2}f(x).\n",
    "$$\n",
    "\n",
    "- TODO: graph\n",
    "\n",
    "- To generalize to a multivariate function $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$, we need notations:  \n",
    "    - **Gradient**:\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\begin{pmatrix}\n",
    "\\frac{\\partial}{\\partial x_1} f(\\mathbf{x}) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial}{\\partial x_n} f(\\mathbf{x})\n",
    "\\end{pmatrix}.\n",
    "$$  \n",
    "    - **Hessian**:\n",
    "$$\n",
    "H(\\mathbf{x}) = \\nabla^2 f(\\mathbf{x}) = \\begin{pmatrix}\n",
    "\\frac{\\partial^2}{\\partial x_1^2} f(\\mathbf{x}) & \\cdots & \\frac{\\partial^2}{\\partial x_1 \\partial x_n} f(\\mathbf{x}) \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial^2}{\\partial x_n \\partial x_1} f(\\mathbf{x}) & \\cdots & \\frac{\\partial^2}{\\partial x_n^2} f(\\mathbf{x})\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "- Example: TODO.\n",
    "\n",
    "- For a sufficiently smooth multivariate function $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$, we have Taylor approximation:  \n",
    "$$\n",
    "f(\\mathbf{x} + \\Delta \\mathbf{x}) \\approx f(\\mathbf{x}) + \\nabla f(\\mathbf{x})' \\Delta \\mathbf{x} + \\frac 12 \\Delta \\mathbf{x}' [\\nabla^2 f(\\mathbf{x})] \\Delta \\mathbf{x}.\n",
    "$$\n",
    "\n",
    "- For a vector function $f: \\mathbb{R}^{n} \\mapsto \\mathbb{R}^m$\n",
    "$$\n",
    "f(\\mathbf{x}) = \\begin{pmatrix} f_1(\\mathbf{x}) \\\\ \\vdots \\\\ f_m(\\mathbf{x}) \\end{pmatrix},\n",
    "$$\n",
    "the $m \\times n$ **Jacobian matrix** is\n",
    "$$\n",
    "\\mathbf{J} = \\begin{pmatrix} \\nabla f_1' \\\\ \\vdots \\\\ \\nabla f_m' \\end{pmatrix} = \\begin{pmatrix}\n",
    "\\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n}\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "The **Jacobian** is the determant of $\\mathbf{J}$ and appears in the multi-dimensional integrals.\n",
    "\n",
    "Later we will develop chain rule for the vector and even matrix functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization and optimality conditions\n",
    "\n",
    "- Optimization aims to minimize a multivariate function $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$ possibly subject to certain constraints. Possible constrains include  \n",
    "    - Linear constraints: $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$.  \n",
    "    - Inequality constraints: $\\mathbf{x} \\ge \\mathbf{0}$.  \n",
    "    - Integer constraints: Each $x_i$ is either 0 or 1.\n",
    "    \n",
    "- Statisticians often talk about _maximization_, because of the maximum likelihood estimation (MLE). Note maximizing $f$ is same as minimizing $-f$. \n",
    "\n",
    "- For unconstrained optimization of a scalar function $f$, we know\n",
    "    - the necessary condition for a point $x$ to be a local minimum is $\\frac{d}{dx} f(x)= 0$.  \n",
    "    - a sufficient condition for a strict local minimum is (1) $\\frac{d}{dx} f(x) = 0$ and (2) $\\frac{d^2}{dx^2} f(x) > 0$.  \n",
    "    These are called the **optimality conditions**.  \n",
    "    \n",
    "- Similarly for unconstrained optimization of a multivariate function $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$,\n",
    "    - the necessary condition for a point $\\mathbf{x}$ to be a local minimum is\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\mathbf{0}_n.\n",
    "$$\n",
    "    - a sufficient condition for a strict local minimum is\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\mathbf{0}_n\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\nabla^2 f(\\mathbf{x}) \\succ \\mathbf{O}_{n \\times n}.\n",
    "$$\n",
    "\n",
    "- A body of work in optimization is to generalize these optimality conditions to the constrained case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convexity\n",
    "\n",
    "- Convexity plays a key role in optimization. \n",
    "\n",
    "    - A **convex set $\\mathcal{K}$**: If $\\mathbf{x}, \\mathbf{y} \\in \\mathcal{K}$, then the line from $\\mathbf{x}$ to $\\mathbf{y}$ $\\{\\alpha \\mathbf{x} + (1 - \\alpha) \\mathbf{y}: \\alpha \\in [0, 1]\\} \\subseteq \\mathcal{K}$.  \n",
    "    - A **convex function $f$**: \n",
    "$$\n",
    "f(\\alpha \\mathbf{x} + (1 - \\alpha) \\mathbf{y}) \\le \\alpha f(\\mathbf{x}) + (1 - \\alpha) f(\\mathbf{y})\n",
    "$$\n",
    "for all $\\mathbf{x}, \\mathbf{y}$ and $\\alpha \\in (0, 1)$.   \n",
    "    - A **strictly convex function** satisifies above definition but replacing $\\le$ by $<$.  \n",
    "    - A **convex function $f$**: The set of points on and above the graph of $f$ is convex.  \n",
    "    - A **smooth and convex $f$**: $f(\\mathbf{x}) \\ge f(\\mathbf{y}) + \\nabla f(\\mathbf{y})' (\\mathbf{x} - \\mathbf{y})$.  The function $f$ sits above its tangent lines.  \n",
    "    \n",
    "- TODO: A convex function sits between its tangent lines and its chords.    \n",
    "\n",
    "- TODO: graph of convex and nonconvex sets/functions.\n",
    "    \n",
    "- Examples: $f_1(x) = ax + b$, $f_2(x) = x^2$, and $f_3(x) = \\max(f_1(x), f_2(x))$.\n",
    "\n",
    "- **Intersection of convex sets is convex.**\n",
    "\n",
    "- **The maximum of two or more convex functions is always convex.**  \n",
    "\n",
    "    Proof: Let $f(\\mathbf{x}) = \\sup_{i \\in \\mathcal{I}} f_i (\\mathbf{x})$. Then\n",
    "$$\n",
    "f_i(\\alpha \\mathbf{x} + (1 - \\alpha) \\mathbf{y}) \\le \\alpha f_i(\\mathbf{x}) + (1 - \\alpha) f_i(\\mathbf{y}) \\le \\alpha f(\\mathbf{x}) + (1 - \\alpha) f(\\mathbf{y})\n",
    "$$\n",
    "for all $i \\in \\mathcal{I}$. Taking supremum over $i$ on the left hand side yields\n",
    "$$\n",
    "f(\\alpha \\mathbf{x} + (1 - \\alpha) \\mathbf{y}) \\le \\alpha f(\\mathbf{x}) + (1 - \\alpha) f(\\mathbf{y}).\n",
    "$$\n",
    "\n",
    "    Note the minimum of convex functions is usually not convex.\n",
    "    \n",
    "- The set of positive (semi)definite matrices is convex.\n",
    "\n",
    "- A twice differentiable function is convex if $\\nabla^2 f(\\mathbf{x}) \\succeq \\mathbf{O}_{n \\times n}$ at all $\\mathbf{x}$. It is strictly convex $\\nabla^2 f(\\mathbf{x}) \\succ \\mathbf{O}_{n \\times n}$ at all $\\mathbf{x}$.\n",
    "\n",
    "- **Convexity prevents two local minima.** For a convex function, any stationary point with $\\nabla f(\\mathbf{x}) = \\mathbf{0}$ is a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimality conditions for constrained optimization\n",
    "\n",
    "- Example:\n",
    "\\begin{eqnarray*}\n",
    "    &\\text{minimize}& f(x_1,x_2) = x_1^2 + x_2^2 \\\\\n",
    "    &\\text{subject to}& a_1 x_1 + a_2 x_2 = b.\n",
    "\\end{eqnarray*}\n",
    "Define the **Lagrangian**\n",
    "$$\n",
    "L(x_1, x_2, \\lambda) = f(x_1, x_2) + \\lambda (a_1 x_1 + a_2 x_2 - b) = x_1^2 + x_2^2 + \\lambda (a_1 x_1 + a_2 x_2 - b)\n",
    "$$\n",
    "where $\\lambda$ is the **Lagrange multiplier**. Solve the equations\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\partial}{\\partial x_1} L &=& 2 x_1 + \\lambda a_1 \\\\\n",
    "\\frac{\\partial}{\\partial x_2} L &=& 2 x_2 + \\lambda a_2 \\\\\n",
    "\\frac{\\partial}{\\partial \\lambda} L &=& a_1 x_1 + a_2 x_2 - b\n",
    "\\end{eqnarray*}\n",
    "to get optimal $x_1$, $x_2$, and $\\lambda$:\n",
    "\\begin{eqnarray*}\n",
    "x_1^\\star &=& \\frac{a_1 b}{a_1^2 + a_2^2} \\\\\n",
    "x_2^\\star &=& \\frac{a_2 b}{a_1^2 + a_2^2} \\\\\n",
    "\\lambda^\\star &=& - \\frac{2b}{a_1^2 + a_2^2}\n",
    "\\end{eqnarray*}\n",
    "with optimal objective value\n",
    "$$\n",
    "(x_1^\\star)^2 + (x_2^\\star)^2 = \\frac{b^2}{a_1^2 + a_2^2}.\n",
    "$$\n",
    "We found **$-\\lambda^\\star$ is simply the derivative of the minimum cost with respect to the constraint level $b$**\n",
    "$$\n",
    "\\frac{d}{d b} \\left( \\frac{b^2}{a_1^2 + a_2^2} \\right) = \\frac{2b}{a_1^2 + a_2^2} = - \\lambda.\n",
    "$$\n",
    "\n",
    "- We generalize above example to the general problem of **minimizing a qaudratic function with linear constraints**.\n",
    "\\begin{eqnarray*}\n",
    "    &\\text{minimize}& \\frac 12 \\mathbf{x}' \\mathbf{S} \\mathbf{x} \\\\\n",
    "    &\\text{subject to}& \\mathbf{A}' \\mathbf{x} = \\mathbf{b}.\n",
    "\\end{eqnarray*}\n",
    "The **Lagrangian** function is\n",
    "$$\n",
    "L(\\mathbf{x}, \\boldsymbol{\\lambda}) = \\frac 12 \\mathbf{x}' \\mathbf{S} \\mathbf{x} + \\boldsymbol{\\lambda}' (\\mathbf{A}' \\mathbf{x} - \\mathbf{b}),\n",
    "$$\n",
    "where $\\boldsymbol{\\lambda} \\in \\mathbb{R}^m$ is the **Lagrange multipliers**. Solving equations\n",
    "\\begin{eqnarray*}\n",
    "    \\frac{\\partial}{\\partial \\mathbf{x}} L &=& \\mathbf{S} \\mathbf{x} + \\mathbf{A} \\boldsymbol{\\lambda} = \\mathbf{0}_n \\\\\n",
    "    \\frac{\\partial}{\\partial \\boldsymbol{\\lambda}} L &=& \\mathbf{A}' \\mathbf{x} - \\mathbf{b} = \\mathbf{0}_m,\n",
    "\\end{eqnarray*}\n",
    "or equivalently\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{S} & \\mathbf{A} \\\\\n",
    "\\mathbf{A}' & \\mathbf{O}\n",
    "\\end{pmatrix} \\begin{pmatrix} \\mathbf{x} \\\\ \\boldsymbol{\\lambda} \\end{pmatrix} = \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{b} \\end{pmatrix} \\quad \\quad (\\text{saddle point matrix or KKT matrix})\n",
    "$$\n",
    "yields the solution\n",
    "\\begin{eqnarray*}\n",
    "\\mathbf{x}^\\star &=& \\mathbf{S}^{-1} \\mathbf{A} (\\mathbf{A}' \\mathbf{S}^{-1} \\mathbf{A})^{-1} \\mathbf{b} \\\\\n",
    "\\boldsymbol{\\lambda}^\\star &=& - (\\mathbf{A}' \\mathbf{S}^{-1} \\mathbf{A})^{-1} \\mathbf{b}.\n",
    "\\end{eqnarray*}\n",
    "Further calculation shows the minimum cost\n",
    "$$\n",
    "f^\\star = \\frac 12 \\mathbf{b}' (\\mathbf{A}' \\mathbf{S}^{-1} \\mathbf{A})^{-1} \\mathbf{b}\n",
    "$$\n",
    "and the gradient of cost\n",
    "$$\n",
    "\\frac{\\partial f^\\star}{\\partial \\mathbf{b}} = (\\mathbf{A}' \\mathbf{S}^{-1} \\mathbf{A})^{-1} \\mathbf{b} = - \\boldsymbol{\\lambda}^\\star.\n",
    "$$\n",
    "\n",
    "- The saddle point matrix (or KKT matrix) has $n$ positive eigenvalues and $m$ negative eigenvalue. The Lagrangian function is convex in $\\mathbf{x}$ and concave in $\\boldsymbol{\\lambda}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: MLE of multivariate normal model\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: MLE of multinomial model\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's method\n",
    "\n",
    "- We are looking for a point $\\mathbf{x}^\\star$ such that $\\nabla f(\\mathbf{x}^\\star) = \\mathbf{0}$. Multivariate calculus gives us a principled way to move towards such an $\\mathbf{x}^\\star$.\n",
    "\n",
    "- Second-order Taylor approximation to a function $f$ at current iterate $\\mathbf{x}^{(t)}$ says\n",
    "$$\n",
    "f(\\mathbf{x}^{(t)} + \\Delta \\mathbf{x}) \\approx f(\\mathbf{x}^{(t)}) + \\nabla f(\\mathbf{x}^{(t)})' \\Delta \\mathbf{x} + \\frac 12 \\Delta \\mathbf{x}' [\\nabla^2 f(\\mathbf{x}^{(t)})] \\Delta \\mathbf{x}.\n",
    "$$\n",
    "Which direction $\\Delta \\mathbf{x}$ shall we move from $\\mathbf{x}^{(t)}$? \n",
    "\n",
    "    Minimizing the quadratic approximation gives the **Newton direction**\n",
    "$$\n",
    "\\Delta \\mathbf{x}_{\\text{newton}} = - [\\nabla^2 f(\\mathbf{x}^{(t)})]^{-1} \\nabla f(\\mathbf{x}^{(t)}).\n",
    "$$\n",
    "\n",
    "- So the **Newton method** iterates according to\n",
    "$$\n",
    "\\mathbf{x}^{(t+1)} = \\mathbf{x}^{(t)} + \\Delta \\mathbf{x}_{\\text{newton}} = \\mathbf{x}^{(t)} - [\\nabla^2 f(\\mathbf{x}^{(t)})]^{-1} \\nabla f(\\mathbf{x}^{(t)}).\n",
    "$$\n",
    "\n",
    "- Quadratic convergence of Newton's method:\n",
    "$$\n",
    "\\|\\mathbf{x}^{(t+1)} - \\mathbf{x}^\\star\\| \\le C \\|\\mathbf{x}^{(t)} - \\mathbf{x}^\\star\\|^2.\n",
    "$$\n",
    "\n",
    "- Example: $f(x) = \\frac 13 x^3 - 4x$ with $\\nabla f(x) = x^2 - 4$ and $\\nabla^2 f(x) = 2x$. Newton's iterates are \n",
    "$$\n",
    "x^{(t+1)} = x^{(t)} - \\frac{x^{(t)2}-4}{2x^{(t)}} = \\frac{1}{2} \\left( x^{(t)} + \\frac{4}{x^{(t)}} \\right).\n",
    "$$\n",
    "Let's start from $x^{(0)}=2.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.05\n",
      "x = 2.000609756097561\n",
      "x = 2.0000000929222947\n",
      "x = 2.000000000000002\n",
      "x = 2.0\n"
     ]
    }
   ],
   "source": [
    "x = 2.5\n",
    "for iter in 1:5\n",
    "    x = 0.5 * (x + 4 / x)\n",
    "    @show x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "x^{(t+1)} - 2 = \\frac 12 \\left( x^{(t)} + \\frac{4}{x^{(t)}} \\right) - 2 = \\frac{1}{2x^{(t)}} \\left( x^{(t)} - 2 \\right)^2\n",
    "$$\n",
    "\n",
    "- In practice, the Newton's method may suffer from **instability**; the iterates may escape into infinities or a local maximum. Two remedies are needed:  \n",
    "    1. Use a positive definite matrix in the quadratic approximation (automatically satisfied by the Hessian of a convex function). \n",
    "    2. Line search (backtracking) to guarantee sufficient drop in the objective function\n",
    "$$\n",
    "f(\\mathbf{x}^{(t)} + s \\Delta \\mathbf{x}) \\le f(\\mathbf{x}^{(t)}) - \\alpha s \\Delta \\mathbf{x}' [\\nabla^2 f(\\mathbf{x}^{(t)})] \\Delta \\mathbf{x}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent algorithm and variants\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
