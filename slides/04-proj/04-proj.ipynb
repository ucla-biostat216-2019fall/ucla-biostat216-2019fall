{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complementary subspaces and projection (BR Chapter 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct sum\n",
    "\n",
    "- BR Theorem 6.1. **Dimension of a sum of subspaces.** Let $\\mathcal{S}_1$ and $\\mathcal{S}_2$ be two subspaces in $\\mathbb{R}^n$. Then\n",
    "$$\n",
    "    \\text{dim}(\\mathcal{S}_1 + \\mathcal{S}_2) = \\text{dim}(\\mathcal{S}_1) + \\text{dim}(\\mathcal{S}_2) - \\text{dim}(\\mathcal{S}_1 \\cap \\mathcal{S}_2).\n",
    "$$\n",
    "\n",
    "    Proof: TODO.\n",
    "    \n",
    "- BR Corollary 6.1.  \n",
    "    1. Let $\\mathcal{S}_1$ and $\\mathcal{S}_2$ be two subspaces in $\\mathbb{R}^n$. Then\n",
    "$$\n",
    "    \\text{dim}(\\mathcal{S}_1 + \\mathcal{S}_2) \\le \\text{dim}(\\mathcal{S}_1) + \\text{dim}(\\mathcal{S}_2).\n",
    "$$   \n",
    "    2. Let $\\mathbf{A}$ and $\\mathbf{B}$ be two matrices of the same order. Then  \n",
    "$$\n",
    "    \\text{rank}(\\mathbf{A} + \\mathbf{B}) \\le \\text{rank}(\\mathbf{A}) + \\text{rank}(\\mathbf{B}).\n",
    "$$\n",
    "\n",
    "    Proof: First claim trivially follows from BR Theorem 6.1. For the second claim. First note $\\mathcal{C}(\\mathbf{A} + \\mathbf{B}) \\subseteq \\mathcal{C}(\\mathbf{A}) + \\mathcal{C}(\\mathbf{B})$ (why). Then\n",
    "    $$\n",
    "        \\text{rank}(\\mathbf{A} + \\mathbf{B}) = \\text{dim}(\\mathcal{C}(\\mathbf{A} + \\mathbf{B})) \\le \\text{dim}(\\mathcal{C}(\\mathbf{A}) + \\mathcal{C}(\\mathbf{B})) \\le \\text{dim}(\\mathcal{C}(\\mathbf{A})) + \\text{dim}(\\mathcal{C}(\\mathbf{B})) = \\text{rank}(\\mathbf{A}) + \\text{rank}(\\mathbf{B}).\n",
    "    $$\n",
    "    \n",
    "- Two subspaces $\\mathcal{S}_1$ and $\\mathcal{S}_2$ in a vector space $\\mathcal{V}$ are said to be **complementary** whenever \n",
    "$$\n",
    "    \\mathcal{V} = \\mathcal{S}_1 + \\mathcal{S}_2 \\text{ and } \\mathcal{S}_1 \\cap \\mathcal{S}_2 = \\{\\mathbf{0}\\}.\n",
    "$$\n",
    "In such cases, we say $\\mathcal{V}$ is a direct sum of $\\mathcal{S}_1$ and $\\mathcal{S}_2$ and denote $\\mathcal{V} = \\mathcal{S}_1 \\oplus \\mathcal{S}_2$. \n",
    "\n",
    "- BR Theorem 6.2. Let $\\mathcal{S}_1, \\mathcal{S}_2$ be two subspaces of $\\mathbb{R}^m$ and $\\mathcal{V} = \\mathcal{S}_1 + \\mathcal{S}_2$. Following statements are equivalent:\n",
    "    1. $\\mathcal{V} = \\mathcal{S}_1 \\oplus \\mathcal{S}_2$. \n",
    "    2. $\\text{dim}(\\mathcal{V}) = \\text{dim}(\\mathcal{S}_1) + \\text{dim}(\\mathcal{S}_2)$.  \n",
    "    3. Any vector $\\mathbf{x} \\in \\mathcal{V}$ can be uniquely represented as\n",
    "    $$\n",
    "        \\mathbf{x} = \\mathbf{x}_1 + \\mathbf{x}_2, \\text{ where } \\mathbf{x}_1 \\in \\mathbf{S}_1, \\mathbf{x}_2 \\in \\mathbf{S}_2.\n",
    "    $$\n",
    "    We will refer to this as the **unique representation** or **unique decomposition** property of direct sums.  \n",
    "    \n",
    "    Proof: We show that $1 \\Rightarrow 2 \\Rightarrow 3 \\Rightarrow 1$.  \n",
    "    $1 \\Rightarrow 2$: By definition of direct sum, we know $\\mathcal{S}_1 \\cap \\mathcal{S}_2 = \\{\\mathbf{0}\\}$. Thus by BR Theorem 6.1, $\\text{dim}(\\mathcal{S}_1 + \\mathcal{S}_2) = \\text{dim}(\\mathcal{S}_1) + \\text{dim}(\\mathcal{S}_2)$.  \\\\\n",
    "    $2 \\Rightarrow 3$: By 2, we know $\\text{dim}(\\mathcal{S}_1 \\cap \\mathcal{S}_2) = 0$ so $\\mathcal{S}_1 \\cap \\mathcal{S}_2 = \\{\\mathbf{0}\\}$. Let $\\mathbf{x} \\in \\mathcal{S}_1 + \\mathcal{S}_2$ and assume $\\mathbf{x}$ can be decomposed in two ways: $\\mathbf{x} = \\mathbf{u}_1 + \\mathbf{u}_2 = \\mathbf{v}_1 + \\mathbf{v}_2$, where $\\mathbf{u}_1, \\mathbf{v}_1 \\in \\mathcal{S}_1$ and $\\mathbf{u}_2, \\mathbf{v}_2 \\in \\mathcal{S}_2$. Then $= \\mathbf{u}_1 - \\mathbf{v}_1 = -(\\mathbf{u}_2 - \\mathbf{v}_2)$, indicating that the vectors $\\mathbf{u}_1 - \\mathbf{v}_1$ and $\\mathbf{u}_2 - \\mathbf{v}_2$ belong to both $\\mathcal{S}_1$ and $\\mathcal{S}_2$ and thus must be $\\mathbf{0}$. Therefore $\\mathbf{u}_1 = \\mathbf{v}_1$ and $\\mathbf{u}_2 = \\mathbf{v}_2$.  \n",
    "    $3 \\Rightarrow 1$: We only need to show $\\mathcal{S}_1 \\cap \\mathcal{S}_2 = \\{\\mathbf{0}\\}$. Let $\\mathbf{x} \\in \\mathcal{S}_1 \\cap \\mathcal{S}_2$. Decompose $\\mathbf{x}$ in two ways: $\\mathbf{x} = \\mathbf{x} + \\mathbf{0} = \\mathbf{0} + \\mathbf{x}$. Then by the uniqueness part of 3, $\\mathbf{x}=\\mathbf{0}$. So the only possible element in $\\mathcal{S}_1 \\cap \\mathcal{S}_2$ is $\\mathbf{0}$.\n",
    "    \n",
    "- Equivalence of properties 1, 2, 3 means we can take any of them to generalize the definition of direct sum to more than two subspaces.\n",
    "\n",
    "- BR Theorem 6.3. Let $\\mathcal{S}_1, \\ldots, \\mathcal{S}_k$ be subspaces of a vector space. Following statements are equivalent:\n",
    "    1. $(\\mathcal{S}_1 + \\cdots + \\mathcal{S}_i) \\cap \\mathcal{S}_{i+1} = \\{\\mathbf{0}\\}$ for $i=1,\\ldots,k-1$.\n",
    "    2. $\\text{dim}(\\mathcal{S}_1 + \\cdots + \\mathcal{S}_k) = \\text{dim}(\\mathcal{S}_1) + \\cdots + \\text{dim}(\\mathcal{S}_k)$.\n",
    "    3. Any vector in $\\mathbf{x} \\in \\mathcal{S}_1 + \\cdots + \\mathcal{S}_k$ can be uniquely expressed as\n",
    "    $$\n",
    "        \\mathbf{x} = \\mathbf{x}_1 + \\cdots + \\mathbf{x}_k, \\text{ where } \\mathbf{x}_i \\in \\mathcal{S}_i, i=1,\\ldots,k.\n",
    "    $$\n",
    "    \n",
    "    Proof: BR p162-163.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection\n",
    "\n",
    "- BR Definition 6.3. Let $\\mathbb{R}^n = \\mathcal{S} \\oplus \\mathcal{T}$ and $\\mathbf{y} = \\mathbf{x} + \\mathbf{z}$ be the unique representation of $\\mathbf{y} \\in \\mathbb{R}^n$ with $\\mathbf{x} \\in \\mathcal{S}$ and $\\mathbf{y} \\in \\mathcal{T}$. Then\n",
    "    - the vector $\\mathbf{x}$ is called the **projection** of $\\mathbf{y}$ into $\\mathcal{S}$ along $\\mathcal{T}$;\n",
    "    - the vector $\\mathbf{z}$ is called the **projection** of $\\mathbf{y}$ into $\\mathcal{T}$ along $\\mathcal{S}$.\n",
    "\n",
    "- Let $\\mathbb{R}^n = \\mathcal{S} \\otimes \\mathcal{T}$. We call a matrix $\\mathbf{P} \\in \\mathbb{R}^{n \\times n}$ a **projector** into $\\mathcal{S}$ along $\\mathcal{T}$ if, for any $\\mathbf{y} \\in \\mathbb{R}^n$, $\\mathbf{P} \\mathbf{y}$ is the projection of $\\mathbf{y}$ into $\\mathcal{S}$ along $\\mathcal{T}$.\n",
    "\n",
    "- BR Corollary 6.5. If $\\mathbf{P}$ is a projector into $\\mathcal{S}$ along $\\mathcal{T}$, then \n",
    "    1. $\\mathbf{P} \\mathbf{x} = \\mathbf{x}$ for all $\\mathbf{x} \\in \\mathcal{S}$.  \n",
    "    2. $\\mathbf{P} \\mathbf{y} = \\mathbf{0}$ for all $\\mathbf{y} \\in \\mathcal{T}$.  \n",
    "\n",
    "    Proof: For 1, since $\\mathbf{x} = \\mathbf{x} + \\mathbf{0}$, where $\\mathbf{x} \\in \\mathcal{S}$ and $\\mathbf{0} \\in \\mathcal{T}$. By uniqueness of the projection, $\\mathbf{P} \\mathbf{x}$ must be equal to $\\mathbf{x}$. For 2, $\\mathbf{y} = \\mathbf{0} + \\mathbf{y}$ is the unique decomposition. Then $\\mathbf{P} \\mathbf{y}$ must be $\\mathbf{0}$.\n",
    "\n",
    "- A square matrix $\\mathbf{P}$ is said to be **idempotent** if $\\mathbf{P}^2 = \\mathbf{P}$.\n",
    "\n",
    "- BR Theorem 6.4. Following statements about a square matrix $\\mathbf{P} \\in \\mathbb{R}^{n \\times n}$ are equivalent:\n",
    "    1. $\\mathbf{P}$ is a projector.  \n",
    "    2. $\\mathbf{P}$ and $\\mathbf{I} - \\mathbf{P}$ are idemponent. That is $\\mathbf{P}^2 = \\mathbf{P}$ and $(\\mathbf{I} - \\mathbf{P})^2 = \\mathbf{I} - \\mathbf{P}$.  \n",
    "    3. $\\mathcal{N}(\\mathbf{P}) = \\mathcal{C}(\\mathbf{I} - \\mathbf{P})$.  \n",
    "    4. $\\text{rank}(\\mathbf{P}) + \\text{rank}(\\mathbf{I} - \\mathbf{P}) = n$.  \n",
    "    5. $\\mathbb{R}^n = \\mathcal{C}(\\mathbf{P}) \\otimes \\mathcal{C}(\\mathbf{I} - \\mathbf{P})$.\n",
    "    \n",
    "    Proof: We show $1 \\Rightarrow 2 \\Rightarrow 3 \\Rightarrow 4 \\Rightarrow 5 \\Rightarrow 1$.  \n",
    "    $1 \\Rightarrow 2$: Suppose $\\mathbf{P}$ is a projector into $\\mathcal{S}$ along $\\mathcal{T}$, where $\\mathcal{S} \\oplus \\mathcal{T} = \\mathbb{R}^n$. By the Lemma, $\\mathbf{P}^2 \\mathbf{y} = \\mathbf{P}(\\mathbf{P} \\mathbf{y}) = \\mathbf{P} \\mathbf{y}$ for any $\\mathbf{y} \\in \\mathbb{R}^n$. Now taking $\\mathbf{y} = \\mathbf{e}_1, \\ldots, \\mathbf{e}_n$, we showed each column of $\\mathbf{P}^2$ is equal to the corresponding column of $\\mathbf{P}$. Therefore $\\mathbf{P}^2 = \\mathbf{P}$. Finally $(\\mathbf{I} - \\mathbf{P})^2 = \\mathbf{I} - 2\\mathbf{P} + \\mathbf{P}^2 = \\mathbf{I} - \\mathbf{P}$.  \n",
    "    $2 \\Rightarrow 3$: To show $\\mathcal{N}(\\mathbf{P}) \\supseteq \\mathcal{C}(\\mathbf{I} - \\mathbf{P})$, \n",
    "    $$\n",
    "        \\mathbf{x} \\in \\mathcal{C}(\\mathbf{I} - \\mathbf{P}) \\Rightarrow \\mathbf{x} = (\\mathbf{I} - \\mathbf{P}) \\mathbf{v} \\text{ for some } \\mathbf{v} \\Rightarrow \\mathbf{P} \\mathbf{x} = \\mathbf{P} (\\mathbf{I} - \\mathbf{P}) \\mathbf{v} = (\\mathbf{P} - \\mathbf{P}^2) \\mathbf{v} = \\mathbf{0}_{n \\times n} \\mathbf{v} = \\mathbf{0} \\Rightarrow \\mathbf{x} \\in \\mathcal{N}(\\mathbf{P}).\n",
    "    $$\n",
    "    To show $\\mathcal{N}(\\mathbf{P}) \\subseteq \\mathcal{C}(\\mathbf{I} - \\mathbf{P})$,\n",
    "    $$\n",
    "        \\mathbf{x} \\in \\mathcal{N}(\\mathbf{P}) \\Rightarrow \\mathbf{P} \\mathbf{x} = \\mathbf{0} \\Rightarrow \\mathbf{x} = \\mathbf{x} - \\mathbf{P} \\mathbf{x} = (\\mathbf{I} - \\mathbf{P}) \\mathbf{x} \\Rightarrow \\mathbf{x} \\in \\mathcal{C}(\\mathbf{I} - \\mathbf{P}).\n",
    "    $$  \n",
    "    $3 \\Rightarrow 4$: By the Rank-Nullity theorem,\n",
    "    $$\n",
    "        \\text{rank}(\\mathbf{P}) = n - \\text{nullity}(\\mathbf{P}) = \\text{dim}(\\mathcal{N}(\\mathbf{P}) = \\text{dim}(\\mathcal{C}(\\mathbf{I} - \\mathbf{P})) = \\text{rank}(\\mathcal{C}(\\mathbf{I} - \\mathbf{P})).\n",
    "    $$  \n",
    "    $4 \\Rightarrow 5$: For any $\\mathbf{x} \\in \\mathbb{R}^n$, $\\mathbf{x} = (\\mathbf{P} + \\mathbf{I} - \\mathbf{P}) \\mathbf{x}  = \\mathbf{P} \\mathbf{x} + (\\mathbf{I} - \\mathbf{P}) \\mathbf{x}$. Thus $\\mathbb{R}^n = \\mathcal{C}(\\mathbf{P}) + \\mathcal{C}(\\mathbf{I} - \\mathbf{P})$. Part 2 of BR Theorem 6.2 then dictates $\\mathbf{P}$ and $\\mathbf{I} - \\mathbf{P}$ must be a direct sum.  \n",
    "    $5 \\Rightarrow 1$: For any $\\mathbf{x} \\in \\mathbb{R}^n$, $\\mathbf{x} = (\\mathbf{P} + \\mathbf{I} - \\mathbf{P}) \\mathbf{x}  = \\mathbf{P} \\mathbf{x} + (\\mathbf{I} - \\mathbf{P}) \\mathbf{x}$, where $\\mathbf{P} \\mathbf{x} \\in \\mathcal{C}(\\mathbf{P})$ and $(\\mathbf{I} - \\mathbf{P}) \\mathbf{x} \\in \\mathcal{C}(\\mathbf{I} - \\mathbf{P})$. 5 then confirms that $\\mathbf{P}$ projects into $\\mathcal{C}(\\mathbf{P})$ along $\\mathcal{C}(\\mathbf{I} - \\mathbf{P})$. \n",
    "    \n",
    "- BR Theorem 6.5. Let $\\mathbf{P}$ be a projector, or equivalently idempotent, then $\\text{tr}(\\mathbf{P}) = \\text{rank}(\\mathbf{P})$.  \n",
    "\n",
    "    Proof: TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
